{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import Bunch\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "import cv2\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"\n",
    "    Load image files with categories as subfolder names \n",
    "    which performs like scikit-learn sample dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_path : string or unicode\n",
    "        Path to the main folder holding one subfolder per category\n",
    "    dimension : tuple\n",
    "        size to which image are adjusted to\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Bunch\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_image_files(container_path, dimension=(70,70)):\n",
    "    image_dir=Path(container_path)\n",
    "    folders=[]\n",
    "    for directory in image_dir.iterdir():\n",
    "            if directory.is_dir():\n",
    "                folders.append(directory);\n",
    "    #print(folders)\n",
    "    categories=[]\n",
    "    for i in  folders:\n",
    "        categories.append(i.name)\n",
    "    #print(categories);\n",
    "    \n",
    "    '''A image classification dataset'''\n",
    "    actual_x = []\n",
    "    actual_y = []\n",
    "    for i, direc in enumerate(folders):\n",
    "        #print(i,direc);\n",
    "        for file in direc.iterdir():\n",
    "            cfile=str(file).replace('\\\\',\"/\")\n",
    "            #print(cfile);\n",
    "            img=cv2.imread(cfile)\n",
    "            #print(img[1]);\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            #print(gray[1])\n",
    "            img_resized = resize(gray, dimension, anti_aliasing=True, mode='reflect')\n",
    "            #print(img_resized[1])\n",
    "            actual_x.append(img_resized.flatten()) \n",
    "            #print(flat_data[0])\n",
    "            actual_y.append(i)\n",
    "    actual_x = np.array(actual_x)\n",
    "    actual_y= np.array(actual_y)\n",
    "    return Bunch(data=actual_x, target=actual_y,target_names=categories)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_dataset = load_image_files(\"traning_image\")\n",
    "\n",
    "#print(image_dataset.data,image_dataset.target,image_dataset.target_names)\n",
    "#test=load_image_files('fdklfd.cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tushar_131']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataset.target_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1564/3132748413.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#print(X_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2175\u001b[1;33m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0m\u001b[0;32m   2176\u001b[0m                                               default_test_size=0.25)\n\u001b[0;32m   2177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1856\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1857\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1858\u001b[0m             \u001b[1;34m'With n_samples={}, test_size={} and train_size={}, the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1859\u001b[0m             \u001b[1;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image_dataset.data, image_dataset.target, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4] 4\n",
      "100 %\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(y_pred,len(y_pred))\n",
    "print(math.ceil(metrics.accuracy_score(y_test, y_pred)*100),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4]\n",
      "100 %\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(y_pred)\n",
    "print(math.ceil(metrics.accuracy_score(y_test, y_pred)*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')#xml file for face detection\n",
    "video_capture = cv2.VideoCapture(0)#open a vedio\n",
    "img_counter = 0 #count level \n",
    "run=0\n",
    "i=0\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()#read a image from vedio\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)#convert to gray scale\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.3, 5)#face size\n",
    "    if len(faces)==0:\n",
    "        continue\n",
    "        \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)#show face position in a frame\n",
    "        roi_gray = gray[y:y+h, x:x+w]#gray scale crop\n",
    "        roi_color = frame[y:y+h, x:x+w]#color image scale crop\n",
    "    k=cv2.waitKey(100)\n",
    "    cv2.imshow('FaceDetection', frame)\n",
    "\n",
    "    i+=1\n",
    "    if i % 20 ==0:\n",
    "        img_name = '.\\\\test_image\\\\face{}.jpg'.format(img_counter)\n",
    "        cv2.imwrite(img_name, roi_gray)\n",
    "        print(f\"{img_name} written!\")\n",
    "        img_counter += 1\n",
    "    if k == 113:\n",
    "        break\n",
    "    \n",
    "        \n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_dir=Path(\"test_image/\")\n",
    "dimension=(70,70)\n",
    "test_x=[]\n",
    "for file in image_dir.iterdir():\n",
    "            cfile=str(file).replace('\\\\',\"/\")\n",
    "            #print(cfile);\n",
    "            img=cv2.imread(cfile)\n",
    "            #print(img[1]);\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            #print(gray[1])\n",
    "            img_resized = resize(gray, dimension, anti_aliasing=True, mode='reflect')\n",
    "            #print(img_resized[1])\n",
    "            test_x.append(img_resized.flatten())\n",
    "#print(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21528/3749471989.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#test_y=[4,4,4,4,4,4,4,4,4,4]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(metrics.accuracy_score(test_y, y_pred))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'logreg' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(test_x)\n",
    "print(y_pred)\n",
    "#test_y=[4,4,4,4,4,4,4,4,4,4]\n",
    "#print(metrics.accuracy_score(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred=np.array(y_pred)\n",
    "counts = np.bincount(y_pred)\n",
    "v=np.argmax(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "name_id=image_dataset.target_names[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tus', '123']\n"
     ]
    }
   ],
   "source": [
    "student=[]\n",
    "for j in name_id.split('_') :\n",
    "            student.append(j)\n",
    "print(student)\n",
    "\n",
    "# student=[]\n",
    "# for j in [ name_id.split('_') for x in image_dataset.target_names ]:\n",
    "#             student.append(j)\n",
    "# print(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tus 123 2022-05-29 20:31:30\n"
     ]
    }
   ],
   "source": [
    "col_names =  ['Id','Name','Date','Time']\n",
    "attendance = pd.DataFrame(columns = col_names)\n",
    "ts = time.time()      \n",
    "date = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d')\n",
    "timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')\n",
    "aa=student[0]\n",
    "Id=student[1]\n",
    "print(aa, Id, date, timeStamp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
