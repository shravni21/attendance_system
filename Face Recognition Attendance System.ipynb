{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import Bunch\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "import cv2 as cv2\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"\"\"\n",
    "    Load image files with categories as subfolder names \n",
    "    which performs like scikit-learn sample dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    container_path : string or unicode\n",
    "        Path to the main folder holding one subfolder per category\n",
    "    dimension : tuple\n",
    "        size to which image are adjusted to\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Bunch\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_image_files(container_path, dimension=(70,70)):\n",
    "    image_dir=Path(container_path)\n",
    "    folders=[]\n",
    "    for directory in image_dir.iterdir():\n",
    "            if directory.is_dir():\n",
    "                folders.append(directory);\n",
    "    #print(folders)\n",
    "    categories=[]\n",
    "    for i in  folders:\n",
    "        categories.append(i.name)\n",
    "    #print(categories);\n",
    "    \n",
    "    '''A image classification dataset'''\n",
    "    actual_x = []\n",
    "    actual_y = []\n",
    "    for i, direc in enumerate(folders):\n",
    "        #print(i,direc);\n",
    "        for file in direc.iterdir():\n",
    "            cfile=str(file).replace('\\\\',\"/\")\n",
    "            #print(cfile);\n",
    "            img=cv2.imread(cfile)\n",
    "            #print(img[1]);\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            #print(gray[1])\n",
    "            img_resized = resize(gray, dimension, anti_aliasing=True, mode='reflect')\n",
    "            #print(img_resized[1])\n",
    "            actual_x.append(img_resized.flatten()) \n",
    "            #print(flat_data[0])\n",
    "            actual_y.append(i)\n",
    "    actual_x = np.array(actual_x)\n",
    "    actual_y= np.array(actual_y)\n",
    "    return Bunch(data=actual_x, target=actual_y,target_names=categories)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_dataset = load_image_files(\"traning_image\")\n",
    "\n",
    "#print(image_dataset.data,image_dataset.target,image_dataset.target_names)\n",
    "#test=load_image_files('fdklfd.cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf_123',\n",
       " 'asd_123',\n",
       " 'hello_123',\n",
       " 'SDF_123',\n",
       " 'shailesh_123',\n",
       " 'shailesh_6872687',\n",
       " 'SHRAVNI_123',\n",
       " 'shravni_427263',\n",
       " 'shravni_432716']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataset.target_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188, 4900)\n",
      "(47, 4900)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(image_dataset.data, image_dataset.target, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "#print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 7 0 2 8 2 4 0 3 7 6 2 0 4 8 2 7 8 6 2 2 6 8 2 8 6 2 2 3 8 3 8 3 2 8 2 7\n",
      " 7 3 7 0 8 2 8 0 8 8] 47\n",
      "92 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(y_pred,len(y_pred))\n",
    "print(math.ceil(metrics.accuracy_score(y_test, y_pred)*100),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 7 0 2 8 2 0 0 3 7 6 2 0 0 8 2 7 6 6 2 2 6 8 2 8 6 2 2 3 8 3 8 3 2 7 2 7\n",
      " 7 3 7 0 6 2 8 0 8 6]\n",
      "79 %\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(y_pred)\n",
    "print(math.ceil(metrics.accuracy_score(y_test, y_pred)*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\test_image\\face0.jpg written!\n",
      ".\\test_image\\face1.jpg written!\n",
      ".\\test_image\\face2.jpg written!\n",
      ".\\test_image\\face3.jpg written!\n",
      ".\\test_image\\face4.jpg written!\n"
     ]
    }
   ],
   "source": [
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')#xml file for face detection\n",
    "video_capture = cv2.VideoCapture(0)#open a vedio\n",
    "img_counter = 0 #count level \n",
    "run=0\n",
    "i=0\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()#read a image from vedio\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)#convert to gray scale\n",
    "    faces = faceCascade.detectMultiScale(gray, 1.3, 5)#face size\n",
    "    if len(faces)==0:\n",
    "        continue\n",
    "        \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)#show face position in a frame\n",
    "        roi_gray = gray[y:y+h, x:x+w]#gray scale crop\n",
    "        roi_color = frame[y:y+h, x:x+w]#color image scale crop\n",
    "    k=cv2.waitKey(100)\n",
    "    cv2.imshow('FaceDetection', frame)\n",
    "    \n",
    "    if img_counter == 5: #ESC Pressed\n",
    "        break\n",
    "    i+=1\n",
    "    if i % 3 ==0:\n",
    "        img_name = '.\\\\test_image\\\\face{}.jpg'.format(img_counter)\n",
    "        cv2.imwrite(img_name, roi_gray)\n",
    "        print(f\"{img_name} written!\")\n",
    "        img_counter += 1\n",
    "    if k == 113:\n",
    "        break\n",
    "    \n",
    "        \n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_dir=Path(\"test_image/\")\n",
    "dimension=(70,70)\n",
    "test_x=[]\n",
    "for file in image_dir.iterdir():\n",
    "            cfile=str(file).replace('\\\\',\"/\")\n",
    "            #print(*image_dir.iterdir());\n",
    "            img=cv2.imread(cfile)\n",
    "            #print(img[1]);\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            #print(gray[1])\n",
    "            img_resized = resize(gray, dimension, anti_aliasing=True, mode='reflect')\n",
    "            #print(img_resized[1])\n",
    "            test_x.append(img_resized.flatten())\n",
    "#print(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 7 7 7 7 2 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(test_x)\n",
    "print(y_pred)\n",
    "#test_y=[4,4,4,4,4,4,4,4,4,4]\n",
    "#print(metrics.accuracy_score(test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred=np.array(y_pred)\n",
    "counts = np.bincount(y_pred)\n",
    "v=np.argmax(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "name_id=image_dataset.target_names[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shravni', '427263']\n"
     ]
    }
   ],
   "source": [
    "student=[]\n",
    "for j in name_id.split('_') :\n",
    "            student.append(j)\n",
    "print(student)\n",
    "\n",
    "# student=[]\n",
    "# for j in [ name_id.split('_') for x in image_dataset.target_names ]:\n",
    "#             student.append(j)\n",
    "# print(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shravni 427263 2022-05-30 12:13:13\n"
     ]
    }
   ],
   "source": [
    "col_names =  ['Id','Name','Date','Time']\n",
    "attendance = pd.DataFrame(columns = col_names)\n",
    "ts = time.time()      \n",
    "date = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d')\n",
    "timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')\n",
    "aa=student[0]\n",
    "Id=student[1]\n",
    "print(aa, Id, date, timeStamp)\n",
    "attendance.loc[len(attendance)] = [Id,aa,date,timeStamp] \n",
    "attendance=attendance.drop_duplicates(subset=['Id'],keep='first')\n",
    "ts = time.time()      \n",
    "date = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d')\n",
    "timeStamp = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')\n",
    "Hour,Minute,Second=timeStamp.split(\":\")\n",
    "fileName=\"Attendance\\Attendance_\"+date+\"_\"+Hour+\"-\"+Minute+\"-\"+Second+\".csv\"\n",
    "attendance.to_csv(fileName,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
